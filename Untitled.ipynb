{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 1000\n",
    "validation_steps = 10\n",
    "learning_rate = 5e-3\n",
    "stochastic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(16)\n",
    "layer = nn.Linear(16, 32).to(device)\n",
    "x = torch.FloatTensor(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundpass(x):\n",
    "    yOut = torch.round(x)\n",
    "    yGrad = x\n",
    "    y = torch.detach(yOut - yGrad) + yGrad\n",
    "    return y\n",
    "\n",
    "class QuantizedLinear(nn.Module):\n",
    "    def __init__(self, original_linear, bitwidth=16):\n",
    "        super(QuantizedLinear, self).__init__()\n",
    "        self.weight = original_linear.weight\n",
    "        self.bias = original_linear.bias\n",
    "        self.Qn = - (2 ** (bitwidth - 1))\n",
    "        self.Qp = 2 ** (bitwidth - 1) - 1\n",
    "        \n",
    "        # Initialize weights\n",
    "        detached_weights = ql.weight.data.cpu().numpy()\n",
    "        step = np.array((2 * np.mean(np.abs(detached_weights))) / np.sqrt(self.Qp))\n",
    "        step = torch.from_numpy(step)\n",
    "        self.register_buffer('step_size', step)\n",
    "        self.step_size.requires_grad = True\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        quantized_weights = self.weight / self.step_size\n",
    "        quantized_weights = torch.clamp(quantized_weights, self.Qn, self.Qp)\n",
    "        quantized_weights = roundpass(quantized_weights)\n",
    "        output = F.linear(inputs, quantized_weights, self.bias)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql = QuantizedLinear(layer).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ql.forward(x)\n",
    "loss = output.sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.step_size.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql.step_size.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643],\n",
       "        [-11446.0273,   3006.7192,   3917.5645,    129.7033,  -1610.7875,\n",
       "           2397.1521,  -2264.2502,   4144.9526,   4077.1482,  -2125.9324,\n",
       "          -1056.8867,  11465.2686,   1488.8735,  -3967.8799,   5313.6401,\n",
       "           3208.3643]], device='cuda:0')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-fd597dbf8335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\snowflaketf2.0\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\snowflaketf2.0\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\snowflaketf2.0\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-fd597dbf8335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-fd597dbf8335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detached_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1e9d78346435>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetached_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'detached_weights' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean(np.abs(detached_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got numpy.float64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b4b9f3254dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQuantizedLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-b55dbf30c4ea>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, original_linear, bitwidth)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdetached_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetached_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): data must be a sequence (got numpy.float64)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23882818,  0.13489422,  0.15865955,  0.19368696,  0.18919614,\n",
       "         0.23255193,  0.18171448,  0.09192187, -0.22875121, -0.06435812,\n",
       "         0.06657663,  0.14900512,  0.07796848,  0.15100685, -0.24461892,\n",
       "         0.0107131 ],\n",
       "       [ 0.02207163, -0.15304941,  0.07893223, -0.16988519,  0.00978947,\n",
       "         0.15209594,  0.07984811,  0.22528166,  0.24292108,  0.09890577,\n",
       "         0.10650149, -0.23040971, -0.06547421,  0.07239476,  0.10172284,\n",
       "        -0.01587471],\n",
       "       [ 0.18991166, -0.24439281,  0.11326149, -0.14285457, -0.09417358,\n",
       "         0.14739051,  0.23646489,  0.2156525 , -0.23469839, -0.00440988,\n",
       "         0.08157218, -0.01371172,  0.02116072, -0.11603403, -0.1272282 ,\n",
       "        -0.02461731],\n",
       "       [ 0.21519399, -0.22859225, -0.14644727,  0.04571882, -0.01975226,\n",
       "         0.2181378 ,  0.09051257,  0.12682173, -0.23262504, -0.04794139,\n",
       "         0.03930071,  0.19086707,  0.11573836,  0.2486201 , -0.15298477,\n",
       "        -0.21225253],\n",
       "       [-0.02800304,  0.2136139 , -0.15284777,  0.09855306,  0.06601813,\n",
       "         0.10886544,  0.11228058,  0.18793917, -0.00857922,  0.10003707,\n",
       "         0.21954748,  0.12104073, -0.15586   ,  0.17059112, -0.23273212,\n",
       "        -0.08283639],\n",
       "       [-0.07229182, -0.24978566,  0.22526082, -0.17964724, -0.10690004,\n",
       "        -0.24987274, -0.1160138 , -0.05990312,  0.15893137,  0.21782714,\n",
       "         0.06068012,  0.11012748, -0.04739559,  0.06091756,  0.07503375,\n",
       "         0.07950306],\n",
       "       [-0.0642589 ,  0.02046022,  0.00487268,  0.20967275,  0.13603622,\n",
       "        -0.2249443 , -0.1247243 , -0.01571155, -0.20303658, -0.10269329,\n",
       "        -0.23907444,  0.22623658, -0.20980093,  0.21765983, -0.10971588,\n",
       "         0.14029083],\n",
       "       [-0.17718542, -0.20572951,  0.02629352,  0.09434488,  0.1353406 ,\n",
       "         0.1702725 , -0.15265015, -0.11033505, -0.15173966, -0.11323223,\n",
       "        -0.15781352, -0.16763836, -0.01841003,  0.12778595,  0.15053862,\n",
       "        -0.09173995],\n",
       "       [ 0.11637539,  0.05376503, -0.14201811,  0.15196112, -0.06037724,\n",
       "        -0.1472657 , -0.09025973, -0.00224659,  0.09150612,  0.16023749,\n",
       "         0.22301224,  0.09181222, -0.02340192, -0.139435  ,  0.2313292 ,\n",
       "         0.12163943],\n",
       "       [ 0.07587221,  0.03610227,  0.10071209, -0.23059645,  0.21386033,\n",
       "         0.23302507,  0.10873991, -0.10784575, -0.09053805,  0.02064526,\n",
       "         0.00098559,  0.0472959 ,  0.14403862,  0.05703002,  0.17853653,\n",
       "        -0.11560857],\n",
       "       [-0.06078595,  0.22978386, -0.12300426,  0.22355765,  0.19151044,\n",
       "        -0.11061284, -0.1960451 , -0.19646344, -0.01983038, -0.23485973,\n",
       "         0.10922465, -0.1832686 , -0.23677647, -0.04198796,  0.05114669,\n",
       "        -0.05853951],\n",
       "       [-0.22999075, -0.11455029, -0.03338373,  0.1925449 , -0.17116979,\n",
       "        -0.09022224,  0.20058092,  0.14798737, -0.09133565,  0.01775634,\n",
       "         0.11394489,  0.08623436,  0.08175486, -0.1346001 , -0.00987124,\n",
       "         0.13178557],\n",
       "       [ 0.17965299, -0.24472648,  0.00403357, -0.24480835, -0.23545223,\n",
       "        -0.07595077, -0.00672674,  0.0770725 , -0.11363703, -0.00677526,\n",
       "         0.06053826, -0.22635531,  0.17489281, -0.18176559, -0.2005058 ,\n",
       "        -0.12611392],\n",
       "       [-0.18703642, -0.18433237,  0.01855654, -0.00389242, -0.14552465,\n",
       "        -0.01537776, -0.00599018,  0.21928915, -0.13553056, -0.11548442,\n",
       "         0.24582565,  0.24144477,  0.07387796, -0.12021607, -0.19150308,\n",
       "        -0.1103844 ],\n",
       "       [-0.11745039,  0.21319202,  0.09296367, -0.09289932, -0.24058464,\n",
       "        -0.1358152 , -0.01812208, -0.08057755,  0.13062653, -0.07791576,\n",
       "         0.199402  , -0.1586482 ,  0.03557387,  0.03305915,  0.05346376,\n",
       "        -0.15837523],\n",
       "       [ 0.01621199, -0.15875578,  0.16074339, -0.07303101,  0.2213718 ,\n",
       "         0.02255532, -0.13784394,  0.09222093,  0.04657331,  0.04525566,\n",
       "        -0.06854874, -0.08006999, -0.06253389,  0.0059011 , -0.04014614,\n",
       "         0.24235195],\n",
       "       [-0.13237458, -0.1558972 , -0.2471075 , -0.22659484, -0.19530764,\n",
       "         0.00602657, -0.17370135, -0.00903028,  0.06837961,  0.02435204,\n",
       "         0.01972041, -0.18544662, -0.10112193,  0.08225814,  0.10185099,\n",
       "        -0.038286  ],\n",
       "       [ 0.05574113,  0.18711647, -0.18045679, -0.09310359,  0.17061323,\n",
       "        -0.24209708,  0.03381896, -0.12610283,  0.11798656, -0.16947833,\n",
       "        -0.08767918,  0.07814652,  0.12437093, -0.10304973, -0.20557597,\n",
       "        -0.14365372],\n",
       "       [ 0.04256475,  0.13938805, -0.18573579,  0.21695262, -0.11601895,\n",
       "        -0.13467786, -0.00447848, -0.20658898,  0.05172497, -0.01428542,\n",
       "        -0.03778782, -0.06795281, -0.05310887,  0.03762364, -0.03060022,\n",
       "        -0.05837324],\n",
       "       [ 0.03771669,  0.13492575,  0.11323541, -0.21734667,  0.06784591,\n",
       "         0.03478491, -0.09451854,  0.037211  ,  0.10283259,  0.23633134,\n",
       "         0.1517778 , -0.06514722,  0.04525632, -0.12550288, -0.14292204,\n",
       "        -0.15307206],\n",
       "       [ 0.11539257, -0.00151303,  0.02607548,  0.17417026,  0.05340773,\n",
       "        -0.12725988, -0.1704565 , -0.22294238,  0.03950217, -0.01268861,\n",
       "         0.03125083,  0.24049014,  0.03862929, -0.12318024,  0.24466416,\n",
       "         0.06142223],\n",
       "       [ 0.12658188,  0.0512397 , -0.05502942,  0.23184255,  0.05139369,\n",
       "         0.22351286,  0.11113712,  0.0091396 , -0.14371753,  0.021543  ,\n",
       "        -0.13079077, -0.00112993,  0.09200835, -0.08647218, -0.2284131 ,\n",
       "         0.19757232],\n",
       "       [-0.02487785, -0.182208  , -0.02651748,  0.22229424,  0.22352353,\n",
       "         0.15263191,  0.04898763, -0.02095914, -0.07705188, -0.11246327,\n",
       "        -0.20571944, -0.04709455,  0.12300518, -0.12697023, -0.23457041,\n",
       "        -0.24920645],\n",
       "       [-0.0879291 , -0.20923972, -0.01946011,  0.1338292 ,  0.19249809,\n",
       "         0.16946658, -0.1221303 , -0.08546039,  0.11971876, -0.20433447,\n",
       "         0.21138924,  0.20468193,  0.12105846,  0.07456896, -0.13368496,\n",
       "         0.22151807],\n",
       "       [-0.11718264,  0.07604462, -0.12836999,  0.02666199, -0.1724748 ,\n",
       "         0.07656422, -0.18716839,  0.14862853, -0.06232929,  0.15314934,\n",
       "         0.00255367, -0.06571499,  0.17311186, -0.00781879,  0.11880141,\n",
       "        -0.1996372 ],\n",
       "       [-0.18094   ,  0.05647999,  0.05679086, -0.22019625, -0.13285524,\n",
       "         0.23361012,  0.21222779, -0.11317244, -0.02189416,  0.23523855,\n",
       "         0.04125261, -0.01590914, -0.11470285, -0.21436602, -0.02476647,\n",
       "         0.24839944],\n",
       "       [-0.02761725,  0.15059447, -0.02024451,  0.01979029,  0.10998935,\n",
       "         0.23449534,  0.1269454 , -0.05737036,  0.05862433,  0.2423572 ,\n",
       "         0.02595887, -0.09589452,  0.13437256,  0.13954091, -0.16640213,\n",
       "         0.08281416],\n",
       "       [-0.15180439,  0.13260347, -0.18585175,  0.08759955,  0.09197497,\n",
       "        -0.09278983, -0.15513793, -0.05017757, -0.22664648,  0.11826655,\n",
       "         0.23132655,  0.02044418, -0.02284035,  0.12188667,  0.08595002,\n",
       "        -0.05162957],\n",
       "       [-0.08162525,  0.16822535,  0.24844977, -0.14825833,  0.08685908,\n",
       "        -0.05952421,  0.03050041, -0.18862474,  0.06246394, -0.2218098 ,\n",
       "         0.11740714, -0.08793509,  0.01086518,  0.03539565,  0.2462287 ,\n",
       "         0.0453271 ],\n",
       "       [-0.14506954, -0.00541061, -0.21880451, -0.10098118, -0.03498164,\n",
       "         0.07796755, -0.17718166,  0.03950009, -0.07290575, -0.23455292,\n",
       "        -0.12662381,  0.1078034 ,  0.01498714,  0.0652312 , -0.13833562,\n",
       "        -0.2085709 ],\n",
       "       [-0.05089304,  0.14538977,  0.05069119,  0.21951106,  0.01354125,\n",
       "        -0.00503314,  0.22410277, -0.05375132,  0.22678718,  0.17563301,\n",
       "        -0.06987038,  0.08070645, -0.13837096, -0.13108891, -0.023119  ,\n",
       "        -0.11427477],\n",
       "       [-0.06405979, -0.0835661 , -0.15686378, -0.16630206,  0.15987271,\n",
       "        -0.20652229,  0.20158151,  0.19427297, -0.09704065,  0.2033369 ,\n",
       "        -0.01217774, -0.11020267,  0.06461573,  0.19050673, -0.19422725,\n",
       "        -0.20814657]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bl = BinarizedLinear(28 * 28, 32, stochastic=stochastic).to(device)\n",
    "# model = dumdums(image_size=28, stochastic=stochastic).to(device)\n",
    "# loss_function = L2SVMLoss().to(device)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
